"""
Script para analisar e explicar as m√©tricas do modelo 2025.
"""

import pandas as pd
import numpy as np
import pickle
from pathlib import Path

BASE_DIR = Path(__file__).parent
MODELS_DIR = BASE_DIR / "models"

def load_metrics():
    """Carrega m√©tricas do modelo treinado."""
    metrics_path = MODELS_DIR / "metrics.pkl"
    
    if not metrics_path.exists():
        print("ERRO: Modelo ainda n√£o foi treinado!")
        print("Execute primeiro: python train_2025.py")
        return None
    
    with open(metrics_path, "rb") as f:
        metrics = pickle.load(f)
    
    return metrics


def explain_metrics(metrics):
    """Explica as m√©tricas do modelo."""
    print("=" * 70)
    print("AN√ÅLISE DAS M√âTRICAS DO MODELO 2025")
    print("=" * 70)
    
    # M√©tricas b√°sicas
    accuracy = metrics['accuracy']
    roc_auc = metrics['roc_auc']
    
    print("\n" + "=" * 70)
    print("1. M√âTRICAS B√ÅSICAS")
    print("=" * 70)
    
    print(f"\nüìä ACCURACY (Precis√£o Geral): {accuracy:.4f} ({accuracy*100:.2f}%)")
    print("   ‚Üí Percentual de predi√ß√µes corretas (OVER e UNDER)")
    print("   ‚Üí Quanto maior, melhor (m√°ximo = 1.0 = 100%)")
    if accuracy >= 0.70:
        print("   ‚úÖ EXCELENTE: Modelo com alta precis√£o geral")
    elif accuracy >= 0.60:
        print("   ‚úÖ BOM: Modelo com boa precis√£o")
    elif accuracy >= 0.50:
        print("   ‚ö†Ô∏è  MODERADO: Melhor que aleat√≥rio, mas pode melhorar")
    else:
        print("   ‚ùå RUIM: Pior que aleat√≥rio (50%)")
    
    print(f"\nüìà ROC-AUC (√Årea sob a Curva ROC): {roc_auc:.4f}")
    print("   ‚Üí Capacidade do modelo de distinguir entre OVER e UNDER")
    print("   ‚Üí Varia de 0.0 a 1.0")
    print("   ‚Üí 0.5 = aleat√≥rio, 1.0 = perfeito")
    if roc_auc >= 0.80:
        print("   ‚úÖ EXCELENTE: Modelo muito bom em distinguir classes")
    elif roc_auc >= 0.70:
        print("   ‚úÖ BOM: Modelo bom em distinguir classes")
    elif roc_auc >= 0.60:
        print("   ‚ö†Ô∏è  MODERADO: Melhor que aleat√≥rio")
    else:
        print("   ‚ùå RUIM: Pr√≥ximo do aleat√≥rio")
    
    # Classification Report
    cr = metrics['classification_report']
    
    print("\n" + "=" * 70)
    print("2. M√âTRICAS POR CLASSE")
    print("=" * 70)
    
    # UNDER
    under_precision = cr['UNDER']['precision']
    under_recall = cr['UNDER']['recall']
    under_f1 = cr['UNDER']['f1-score']
    under_support = cr['UNDER']['support']
    
    print(f"\nüìâ CLASSE: UNDER (total_kills <= m√©dia da liga)")
    print(f"   Precision: {under_precision:.4f} ({under_precision*100:.2f}%)")
    print("   ‚Üí Quando o modelo prediz UNDER, est√° correto X% das vezes")
    print(f"   Recall: {under_recall:.4f} ({under_recall*100:.2f}%)")
    print("   ‚Üí O modelo identifica X% de todos os casos UNDER reais")
    print(f"   F1-Score: {under_f1:.4f}")
    print("   ‚Üí M√©dia harm√¥nica entre Precision e Recall")
    print(f"   Support: {under_support} amostras")
    
    # OVER
    over_precision = cr['OVER']['precision']
    over_recall = cr['OVER']['recall']
    over_f1 = cr['OVER']['f1-score']
    over_support = cr['OVER']['support']
    
    print(f"\nüìà CLASSE: OVER (total_kills > m√©dia da liga)")
    print(f"   Precision: {over_precision:.4f} ({over_precision*100:.2f}%)")
    print("   ‚Üí Quando o modelo prediz OVER, est√° correto X% das vezes")
    print(f"   Recall: {over_recall:.4f} ({over_recall*100:.2f}%)")
    print("   ‚Üí O modelo identifica X% de todos os casos OVER reais")
    print(f"   F1-Score: {over_f1:.4f}")
    print("   ‚Üí M√©dia harm√¥nica entre Precision e Recall")
    print(f"   Support: {over_support} amostras")
    
    # Confusion Matrix
    cm = metrics['confusion_matrix']
    tn, fp, fn, tp = cm[0][0], cm[0][1], cm[1][0], cm[1][1]
    total = tn + fp + fn + tp
    
    print("\n" + "=" * 70)
    print("3. MATRIZ DE CONFUS√ÉO")
    print("=" * 70)
    
    print(f"\n                Predito")
    print(f"              UNDER  OVER")
    print(f"    Real UNDER   {tn:4d}   {fp:4d}")
    print(f"         OVER    {fn:4d}   {tp:4d}")
    
    print(f"\nüìä INTERPRETA√á√ÉO:")
    print(f"   ‚úÖ True Negatives (TN): {tn} - UNDER predito corretamente")
    print(f"   ‚ùå False Positives (FP): {fp} - OVER predito incorretamente (era UNDER)")
    print(f"   ‚ùå False Negatives (FN): {fn} - UNDER predito incorretamente (era OVER)")
    print(f"   ‚úÖ True Positives (TP): {tp} - OVER predito corretamente")
    
    # Taxas derivadas
    print("\n" + "=" * 70)
    print("4. TAXAS DERIVADAS")
    print("=" * 70)
    
    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0
    
    print(f"\nüéØ Specificity (Taxa de Verdadeiros Negativos): {specificity:.4f}")
    print("   ‚Üí Capacidade de identificar corretamente casos UNDER")
    print("   ‚Üí IMPORTANTE: Evita apostas erradas em UNDER quando deveria ser OVER")
    
    print(f"\nüéØ Sensitivity/Recall (Taxa de Verdadeiros Positivos): {sensitivity:.4f}")
    print("   ‚Üí Capacidade de identificar corretamente casos OVER")
    print("   ‚Üí IMPORTANTE: Identifica oportunidades de apostar em OVER")
    
    # An√°lise de balanceamento
    print("\n" + "=" * 70)
    print("5. AN√ÅLISE DE BALANCEAMENTO")
    print("=" * 70)
    
    under_pct = (tn + fp) / total * 100
    over_pct = (fn + tp) / total * 100
    
    print(f"\nüìä Distribui√ß√£o das classes no conjunto de teste:")
    print(f"   UNDER: {tn + fp} amostras ({under_pct:.1f}%)")
    print(f"   OVER: {fn + tp} amostras ({over_pct:.1f}%)")
    
    if abs(under_pct - over_pct) < 10:
        print("   ‚úÖ Classes bem balanceadas")
    else:
        print("   ‚ö†Ô∏è  Classes desbalanceadas - modelo usa class_weight='balanced'")
    
    # Resumo final
    print("\n" + "=" * 70)
    print("6. RESUMO E RECOMENDA√á√ïES")
    print("=" * 70)
    
    print(f"\n‚úÖ PONTOS FORTES:")
    if accuracy >= 0.65:
        print(f"   ‚Ä¢ Accuracy de {accuracy*100:.1f}% indica boa capacidade preditiva")
    if roc_auc >= 0.70:
        print(f"   ‚Ä¢ ROC-AUC de {roc_auc:.3f} mostra boa separa√ß√£o entre classes")
    if under_precision >= 0.65 and over_precision >= 0.65:
        print("   ‚Ä¢ Boa precis√£o em ambas as classes")
    
    print(f"\n‚ö†Ô∏è  PONTOS DE ATEN√á√ÉO:")
    if accuracy < 0.60:
        print("   ‚Ä¢ Accuracy abaixo de 60% - considerar mais features ou dados")
    if roc_auc < 0.65:
        print("   ‚Ä¢ ROC-AUC baixo - modelo pode estar subajustado")
    if abs(under_precision - over_precision) > 0.15:
        print("   ‚Ä¢ Grande diferen√ßa entre precis√µes - modelo pode ter vi√©s")
    
    print(f"\nüí° COMO USAR O MODELO:")
    print("   ‚Ä¢ Use probabilidades acima de 55% para apostas com confian√ßa m√©dia")
    print("   ‚Ä¢ Use probabilidades acima de 70% para apostas com alta confian√ßa")
    print("   ‚Ä¢ Evite apostar quando probabilidade estiver entre 45-55%")
    print("   ‚Ä¢ Considere o contexto da liga e dos times antes de apostar")
    
    print("\n" + "=" * 70)


def main():
    """Fun√ß√£o principal."""
    metrics = load_metrics()
    
    if metrics is None:
        return
    
    explain_metrics(metrics)


if __name__ == "__main__":
    main()
