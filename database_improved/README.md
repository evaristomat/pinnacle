# ğŸ“Š Sistema de Processamento de Dados HistÃ³ricos de LoL

Sistema melhorado para baixar, processar e organizar dados histÃ³ricos de jogos de League of Legends para anÃ¡lise de apostas.

## ğŸš€ InÃ­cio RÃ¡pido

### InstalaÃ§Ã£o

```bash
# Instalar dependÃªncias
pip install -r requirements.txt
```

### Uso BÃ¡sico

```bash
# Executar pipeline completo (download â†’ clean â†’ ligas)
python main.py
```

## ğŸ“ Estrutura

```
database_improved/
â”œâ”€â”€ config.py              # ConfiguraÃ§Ãµes centralizadas
â”œâ”€â”€ download.py             # Download do CSV do Google Drive
â”œâ”€â”€ clean_database.py       # Processamento e limpeza de dados
â”œâ”€â”€ ligas.py                # GeraÃ§Ã£o de mapeamento liga â†’ times
â”œâ”€â”€ main.py                 # Pipeline completo (orquestrador)
â”œâ”€â”€ database_schema.py       # Schema SQLite (opcional)
â”œâ”€â”€ requirements.txt        # DependÃªncias Python
â””â”€â”€ README.md              # Esta documentaÃ§Ã£o
```

## ğŸ”„ Fluxo de Trabalho

```
1. download.py
   â†“
   database.csv (dados brutos do Google Drive)
   
2. clean_database.py
   â†“
   data_transformed.csv (dados limpos, formato matchup)
   
3. ligas.py
   â†“
   ligas_times.json (mapeamento liga â†’ times)
```

## ğŸ“ Uso Detalhado

### Pipeline Completo

```bash
python main.py
```

Executa todas as etapas em sequÃªncia:
1. **Download**: Baixa `database.csv` do Google Drive
2. **Limpeza**: Processa e transforma dados
3. **Ligas**: Gera mapeamento de times por liga

### Etapas Individuais

```bash
# Apenas download
python main.py --download-only

# Apenas limpeza (requer database.csv existente)
python main.py --clean-only

# Apenas geraÃ§Ã£o de ligas (requer data_transformed.csv existente)
python main.py --ligas-only

# Pula download (usa CSV existente)
python main.py --skip-download
```

### Scripts Individuais

```bash
# Download
python download.py

# Processamento
python clean_database.py

# GeraÃ§Ã£o de ligas
python ligas.py
```

## ğŸ“Š Arquivos Gerados

### `database.csv`
- **Fonte**: Google Drive
- **Formato**: Dados brutos (uma linha por jogador por partida)
- **Tamanho**: ~70-75 MB
- **Uso**: Fonte de dados original

### `data_transformed.csv`
- **Fonte**: Processamento de `database.csv`
- **Formato**: Dados limpos (uma linha por partida/matchup)
- **Tamanho**: ~2-3 MB
- **Uso**: Dados prontos para anÃ¡lise de apostas
- **Colunas principais**:
  - `league`, `year`, `date`
  - `t1`, `t2` (times)
  - `result_t1` (0 = perdeu, 1 = ganhou)
  - `top_t1`, `jung_t1`, `mid_t1`, `adc_t1`, `sup_t1` (composiÃ§Ã£o time 1)
  - `top_t2`, `jung_t2`, `mid_t2`, `adc_t2`, `sup_t2` (composiÃ§Ã£o time 2)
  - `total_kills`, `total_barons`, `total_towers`, etc.

### `ligas_times.json`
- **Fonte**: Processamento de `data_transformed.csv`
- **Formato**: JSON com mapeamento liga â†’ lista de times
- **Uso**: ReferÃªncia para identificar diferenÃ§as de escrita entre sites de apostas
- **Exemplo**:
```json
{
  "LEC": ["Fnatic", "G2 Esports", "Karmine Corp", ...],
  "LCK": ["T1", "Gen.G", "Dplus KIA", ...]
}
```

## ğŸ—„ï¸ Banco de Dados SQLite (Opcional)

Para melhor performance em consultas, vocÃª pode migrar para SQLite:

```bash
# Inicializar banco
python database_schema.py init

# Importar CSV para banco
python database_schema.py import

# Ver estatÃ­sticas
python database_schema.py stats
```

### Estrutura do Banco

- **`matchups`**: Tabela principal com informaÃ§Ãµes dos jogos
- **`compositions`**: ComposiÃ§Ãµes de champions por time
- **`leagues_teams`**: Cache de times por liga

### Consultas Ãšteis

```python
import sqlite3
import pandas as pd

conn = sqlite3.connect('lol_history.db')

# Matchups de uma liga
df = pd.read_sql_query("""
    SELECT * FROM matchups 
    WHERE league = 'LEC' AND year = 2025
    ORDER BY date DESC
""", conn)

# EstatÃ­sticas de um time
df = pd.read_sql_query("""
    SELECT 
        COUNT(*) as total_games,
        SUM(CASE WHEN t1 = 'G2 Esports' AND result_t1 = 1 THEN 1 
                 WHEN t2 = 'G2 Esports' AND result_t1 = 0 THEN 1 
                 ELSE 0 END) as wins
    FROM matchups
    WHERE t1 = 'G2 Esports' OR t2 = 'G2 Esports'
""", conn)
```

## âš™ï¸ ConfiguraÃ§Ã£o

Todas as configuraÃ§Ãµes estÃ£o centralizadas em `config.py`:

```python
# Google Drive
GOOGLE_DRIVE_FILE_ID = "1hnpbrUpBMS1TZI7IovfpKeZfWJH1Aptm"

# Arquivos
DATABASE_CSV = "database.csv"
TRANSFORMED_CSV = "data_transformed.csv"
LIGAS_JSON = "ligas_times.json"
SQLITE_DB = "lol_history.db"
```

## ğŸ” ValidaÃ§Ã£o e Logging

- **ValidaÃ§Ã£o de dados**: Verifica estrutura do CSV antes de processar
- **Logging**: Registra todas as operaÃ§Ãµes em `data_processing.log`
- **Hash MD5**: Verifica integridade dos arquivos baixados
- **Tratamento de erros**: Mensagens claras e recuperaÃ§Ã£o de falhas

## ğŸ“ˆ Melhorias Implementadas

### vs. VersÃ£o Original

âœ… **ConfiguraÃ§Ã£o centralizada** (`config.py`)  
âœ… **ValidaÃ§Ã£o de dados** antes de processar  
âœ… **Tratamento robusto de erros**  
âœ… **Logging estruturado**  
âœ… **Pipeline automatizado** (`main.py`)  
âœ… **VerificaÃ§Ã£o de integridade** (hash MD5)  
âœ… **Progress bars** e feedback visual  
âœ… **DocumentaÃ§Ã£o completa**  
âœ… **Suporte a SQLite** (opcional, melhor performance)  

## ğŸ› Troubleshooting

### Erro: "Arquivo nÃ£o encontrado"
- Verifique se executou `download.py` primeiro
- Use `python main.py` para pipeline completo

### Erro: "Colunas faltando"
- O CSV pode estar desatualizado
- Baixe novamente com `python download.py`

### Erro: "Timeout no download"
- Verifique conexÃ£o com internet
- O arquivo Ã© grande (~70 MB), pode demorar

### Performance lenta
- Considere usar SQLite: `python database_schema.py import`
- Consultas SQL sÃ£o 10-100x mais rÃ¡pidas que CSV

## ğŸ“š Exemplos de Uso

### AnÃ¡lise de Matchups

```python
import pandas as pd

# Carrega dados limpos
df = pd.read_csv('data_transformed.csv')

# Filtra por liga
lec_games = df[df['league'] == 'LEC']

# AnÃ¡lise de vitÃ³rias
win_rate = lec_games.groupby('t1')['result_t1'].mean()
```

### Identificar DiferenÃ§as de Nomes

```python
import json

# Carrega mapeamento
with open('ligas_times.json', 'r', encoding='utf-8') as f:
    ligas = json.load(f)

# Busca time em todas as ligas
team_name = "G2"
for liga, times in ligas.items():
    matches = [t for t in times if team_name.lower() in t.lower()]
    if matches:
        print(f"{liga}: {matches}")
```

## ğŸ”— IntegraÃ§Ã£o com Projeto Principal

Este sistema Ã© independente do projeto `pinnacle` (odds da Pinnacle), mas pode ser integrado:

1. Use `data_transformed.csv` para anÃ¡lise histÃ³rica
2. Use `ligas_times.json` para normalizar nomes de times
3. Use SQLite para consultas rÃ¡pidas em grandes volumes

## ğŸ“ Notas

- O arquivo `database.csv` Ã© atualizado periodicamente no Google Drive
- Execute o pipeline regularmente para manter dados atualizados
- `ligas_times.json` Ã© Ãºtil para identificar variaÃ§Ãµes de nomes entre sites
- SQLite Ã© opcional mas recomendado para grandes volumes de dados

## ğŸ“„ LicenÃ§a

Este cÃ³digo faz parte do projeto Pinnacle.

---

**Ãšltima atualizaÃ§Ã£o**: 2026-01-22
